# 04_å•å¼ é¢„æµ‹.py
"""
å•å¼ å›¾ç‰‡é¢„æµ‹æ¨¡å— - ä½¿ç”¨è®­ç»ƒå¥½çš„æ¨¡å‹é¢„æµ‹å•å¼ å›¾ç‰‡
ä½¿ç”¨æ–¹æ³•: python 04_å•å¼ é¢„æµ‹.py --image å›¾ç‰‡è·¯å¾„
æˆ–: python 04_å•å¼ é¢„æµ‹.py (ä¼šä½¿ç”¨test_imagesç›®å½•ä¸‹çš„å›¾ç‰‡)
"""

import torch
import torch.nn as nn
from torchvision import models, transforms
from PIL import Image, ImageDraw, ImageFont
import argparse
import os
import glob
import numpy as np
import matplotlib.pyplot as plt

class CataractPredictor:
    """ç™½å†…éšœé¢„æµ‹å™¨"""
    
    def __init__(self, model_path='models/cataract_resnet18.pth'):
        """åˆå§‹åŒ–é¢„æµ‹å™¨"""
        self.model_path = model_path
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.classes = ['ç™½å†…éšœ', 'æ­£å¸¸']  # ä¸­æ–‡æ˜¾ç¤º
        
        # å›¾åƒé¢„å¤„ç†
        self.transform = transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ])
        
        # åŠ è½½æ¨¡å‹
        self.load_model()
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print(f"åŠ è½½æ¨¡å‹: {self.model_path}")
        
        if not os.path.exists(self.model_path):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {self.model_path}")
            print("è¯·å…ˆè¿è¡Œ 02_æ¨¡å‹è®­ç»ƒ.py è®­ç»ƒæ¨¡å‹")
            return False
        
        try:
            # æ„å»ºæ¨¡å‹ç»“æ„
            model = models.resnet18(pretrained=False)
            num_features = model.fc.in_features
            model.fc = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(num_features, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 2)
            )
            
            # åŠ è½½æƒé‡
            checkpoint = torch.load(self.model_path, map_location=self.device)
            model.load_state_dict(checkpoint['model_state_dict'])
            model = model.to(self.device)
            model.eval()
            
            self.model = model
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   è®¾å¤‡: {self.device}")
            
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def predict_image(self, image_path):
        """é¢„æµ‹å•å¼ å›¾ç‰‡"""
        if not self.model:
            print("âŒ é”™è¯¯: æ¨¡å‹æœªåŠ è½½")
            return None
        
        try:
            # åŠ è½½å’Œé¢„å¤„ç†å›¾ç‰‡
            image = Image.open(image_path).convert('RGB')
            original_image = image.copy()
            input_tensor = self.transform(image).unsqueeze(0).to(self.device)
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(input_tensor)
                probs = torch.nn.functional.softmax(outputs, dim=1)
                _, predicted = torch.max(outputs, 1)
            
            # è·å–é¢„æµ‹ç»“æœ
            class_index = predicted.item()
            class_name = self.classes[class_index]
            confidence = probs[0][class_index].item()
            
            # è·å–æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
            all_probs = probs[0].cpu().numpy()
            
            return {
                'image_path': image_path,
                'class_index': class_index,
                'class_name': class_name,
                'confidence': confidence,
                'all_probs': all_probs,
                'original_image': original_image
            }
            
        except Exception as e:
            print(f"âŒ é¢„æµ‹å›¾ç‰‡å¤±è´¥: {e}")
            return None
    
    def visualize_prediction(self, result, save_path=None):
        """å¯è§†åŒ–é¢„æµ‹ç»“æœ"""
        if not result:
            return
        
        # åˆ›å»ºå›¾å½¢
        fig, axes = plt.subplots(1, 2, figsize=(12, 5))
        
        # å·¦ä¾§ï¼šæ˜¾ç¤ºå›¾ç‰‡å’Œé¢„æµ‹ç»“æœ
        axes[0].imshow(result['original_image'])
        axes[0].axis('off')
        
        # æ·»åŠ é¢„æµ‹ç»“æœæ–‡æœ¬
        prediction_text = f"é¢„æµ‹: {result['class_name']}\nç½®ä¿¡åº¦: {result['confidence']:.1%}"
        axes[0].set_title('è¾“å…¥å›¾ç‰‡', fontsize=14, fontweight='bold')
        axes[0].text(0.5, -0.1, prediction_text, 
                    transform=axes[0].transAxes,
                    fontsize=12, ha='center',
                    bbox=dict(boxstyle='round', facecolor='yellow', alpha=0.5))
        
        # å³ä¾§ï¼šæ˜¾ç¤ºæ¦‚ç‡æ¡å½¢å›¾
        classes = ['ç™½å†…éšœ', 'æ­£å¸¸']
        colors = ['red', 'green']
        
        bars = axes[1].bar(classes, result['all_probs'], color=colors, alpha=0.7)
        axes[1].set_ylim([0, 1])
        axes[1].set_ylabel('æ¦‚ç‡', fontsize=12)
        axes[1].set_title('ç±»åˆ«æ¦‚ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        axes[1].grid(True, alpha=0.3, axis='y')
        
        # åœ¨æŸ±çŠ¶å›¾ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for bar, prob in zip(bars, result['all_probs']):
            height = bar.get_height()
            axes[1].text(bar.get_x() + bar.get_width()/2., height + 0.01,
                        f'{prob:.1%}', ha='center', va='bottom', fontsize=10)
        
        plt.suptitle('ç™½å†…éšœç­›æŸ¥é¢„æµ‹ç»“æœ', fontsize=16, fontweight='bold')
        plt.tight_layout()
        
        # ä¿å­˜æˆ–æ˜¾ç¤º
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"âœ… é¢„æµ‹ç»“æœå›¾å·²ä¿å­˜åˆ° {save_path}")
        else:
            plt.show()
        
        plt.close()
    
    def predict_and_save(self, image_path, output_dir='results/predictions'):
        """é¢„æµ‹å›¾ç‰‡å¹¶ä¿å­˜ç»“æœ"""
        # åˆ›å»ºè¾“å‡ºç›®å½•
        os.makedirs(output_dir, exist_ok=True)
        
        # é¢„æµ‹å›¾ç‰‡
        result = self.predict_image(image_path)
        if not result:
            return
        
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶å
        filename = os.path.basename(image_path)
        name, ext = os.path.splitext(filename)
        output_path = os.path.join(output_dir, f"{name}_prediction.png")
        
        # å¯è§†åŒ–å¹¶ä¿å­˜
        self.visualize_prediction(result, save_path=output_path)
        
        # æ‰“å°ç»“æœ
        print(f"\nğŸ“Š é¢„æµ‹ç»“æœ:")
        print(f"  å›¾ç‰‡: {filename}")
        print(f"  é¢„æµ‹ç±»åˆ«: {result['class_name']}")
        print(f"  ç½®ä¿¡åº¦: {result['confidence']:.1%}")
        print(f"  ç™½å†…éšœæ¦‚ç‡: {result['all_probs'][0]:.1%}")
        print(f"  æ­£å¸¸æ¦‚ç‡: {result['all_probs'][1]:.1%}")
        
        # åŒ»å­¦å»ºè®®
        if result['class_name'] == 'ç™½å†…éšœ':
            print(f"\nâš ï¸ åŒ»å­¦å»ºè®®: æ£€æµ‹åˆ°ç™½å†…éšœç‰¹å¾ï¼Œå»ºè®®è¿›è¡Œè¿›ä¸€æ­¥çœ¼ç§‘æ£€æŸ¥ã€‚")
        else:
            print(f"\nâœ… åŒ»å­¦å»ºè®®: æœªæ£€æµ‹åˆ°æ˜æ˜¾ç™½å†…éšœç‰¹å¾ã€‚")
        
        return result

def process_single_image(image_path, predictor):
    """å¤„ç†å•å¼ å›¾ç‰‡"""
    print(f"\nå¤„ç†å›¾ç‰‡: {image_path}")
    
    if not os.path.exists(image_path):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°å›¾ç‰‡ {image_path}")
        return
    
    result = predictor.predict_and_save(image_path)
    return result

def process_directory(image_dir, predictor):
    """å¤„ç†ç›®å½•ä¸­çš„æ‰€æœ‰å›¾ç‰‡"""
    print(f"\nå¤„ç†ç›®å½•: {image_dir}")
    
    if not os.path.exists(image_dir):
        print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°ç›®å½• {image_dir}")
        return []
    
    # æ”¯æŒçš„å›¾ç‰‡æ ¼å¼
    image_extensions = ['*.jpg', '*.jpeg', '*.png', '*.bmp', '*.tiff']
    image_files = []
    
    for ext in image_extensions:
        image_files.extend(glob.glob(os.path.join(image_dir, ext)))
    
    if not image_files:
        print(f"âŒ é”™è¯¯: ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶")
        return []
    
    print(f"æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    
    results = []
    for image_path in image_files:
        result = process_single_image(image_path, predictor)
        if result:
            results.append(result)
    
    return results

def batch_statistics(results):
    """æ‰¹é‡é¢„æµ‹ç»Ÿè®¡"""
    if not results:
        return
    
    print("\n" + "="*60)
    print("æ‰¹é‡é¢„æµ‹ç»Ÿè®¡")
    print("="*60)
    
    cataract_count = sum(1 for r in results if r['class_name'] == 'ç™½å†…éšœ')
    normal_count = sum(1 for r in results if r['class_name'] == 'æ­£å¸¸')
    
    print(f"æ€»å›¾ç‰‡æ•°: {len(results)}")
    print(f"ç™½å†…éšœé¢„æµ‹æ•°: {cataract_count}")
    print(f"æ­£å¸¸é¢„æµ‹æ•°: {normal_count}")
    print(f"ç™½å†…éšœæ¯”ä¾‹: {cataract_count/len(results):.1%}")
    
    # å¹³å‡ç½®ä¿¡åº¦
    cataract_conf = [r['confidence'] for r in results if r['class_name'] == 'ç™½å†…éšœ']
    normal_conf = [r['confidence'] for r in results if r['class_name'] == 'æ­£å¸¸']
    
    if cataract_conf:
        print(f"ç™½å†…éšœå¹³å‡ç½®ä¿¡åº¦: {np.mean(cataract_conf):.1%}")
    if normal_conf:
        print(f"æ­£å¸¸å¹³å‡ç½®ä¿¡åº¦: {np.mean(normal_conf):.1%}")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='ç™½å†…éšœç­›æŸ¥ - å•å¼ å›¾ç‰‡é¢„æµ‹')
    parser.add_argument('--image', type=str, help='è¦é¢„æµ‹çš„å›¾ç‰‡è·¯å¾„')
    parser.add_argument('--dir', type=str, default='test_images', 
                       help='åŒ…å«æµ‹è¯•å›¾ç‰‡çš„ç›®å½• (é»˜è®¤: test_images)')
    parser.add_argument('--model', type=str, default='models/cataract_resnet18.pth',
                       help='æ¨¡å‹è·¯å¾„ (é»˜è®¤: models/cataract_resnet18.pth)')
    
    args = parser.parse_args()
    
    print("="*70)
    print("ç™½å†…éšœç­›æŸ¥ - å•å¼ å›¾ç‰‡é¢„æµ‹")
    print("="*70)
    
    # åˆ›å»ºé¢„æµ‹å™¨
    predictor = CataractPredictor(model_path=args.model)
    
    if not predictor.model:
        return
    
    # åˆ›å»ºæµ‹è¯•å›¾ç‰‡ç›®å½•
    os.makedirs('test_images', exist_ok=True)
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šå›¾ç‰‡ï¼Œæ£€æŸ¥test_imagesç›®å½•
    if not args.image:
        test_files = glob.glob(os.path.join('test_images', '*.*'))
        if test_files:
            print(f"å‘ç° {len(test_files)} å¼ æµ‹è¯•å›¾ç‰‡")
            for i, img in enumerate(test_files[:3]):  # åªæ˜¾ç¤ºå‰3å¼ 
                print(f"  {i+1}. {os.path.basename(img)}")
            print("\nè¯·è¾“å…¥ --image å‚æ•°æŒ‡å®šå›¾ç‰‡ï¼Œæˆ–å°†è¦é¢„æµ‹çš„å›¾ç‰‡æ”¾å…¥ test_images ç›®å½•")
            print("ç¤ºä¾‹: python 04_å•å¼ é¢„æµ‹.py --image test_images/your_image.jpg")
        else:
            print("\nâŒ æ²¡æœ‰æ‰¾åˆ°æµ‹è¯•å›¾ç‰‡")
            print("è¯·å°†è¦é¢„æµ‹çš„å›¾ç‰‡æ”¾å…¥ test_images ç›®å½•ï¼Œæˆ–ä½¿ç”¨ --image å‚æ•°æŒ‡å®šå›¾ç‰‡")
        return
    
    # å¤„ç†å•ä¸ªå›¾ç‰‡
    if args.image:
        result = process_single_image(args.image, predictor)
        if result:
            print(f"\nâœ… é¢„æµ‹å®Œæˆ!")
    else:
        # å¤„ç†æ•´ä¸ªç›®å½•
        results = process_directory(args.dir, predictor)
        if results:
            batch_statistics(results)

if __name__ == "__main__":
    main()