# 03_ä¿®å¤å¤æ‚å›¾è¡¨ç‰ˆæ¨¡å‹è¯„ä¼°.py
"""
ä¿®å¤å¤æ‚å›¾è¡¨ç‰ˆæ¨¡å‹è¯„ä¼°æ¨¡å— - ä¿ç•™äº†æ‰€æœ‰å¤æ‚å›¾è¡¨ï¼Œä¿®å¤äº†æ•°ç»„å½¢çŠ¶é—®é¢˜

"""

import torch
import torch.nn as nn
from torchvision import models, transforms
from torch.utils.data import DataLoader

import os
import sys
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

def get_script_dir():
    """è·å–è„šæœ¬æ‰€åœ¨ç›®å½•"""
    return os.path.dirname(os.path.abspath(__file__))

class CataractDataset:
    """ç™½å†…éšœæ•°æ®é›†ç±»"""
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.classes = ['cataract', 'normal']
        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}
        
        self.images = []
        self.labels = []
        self.image_paths = []
        
        # éå†æ‰€æœ‰ç±»åˆ«
        for class_name in self.classes:
            class_dir = os.path.join(root_dir, class_name)
            if not os.path.exists(class_dir):
                print(f"âš ï¸ è­¦å‘Š: æ‰¾ä¸åˆ°ç±»åˆ«ç›®å½• {class_dir}")
                continue
                
            img_files = [f for f in os.listdir(class_dir) 
                        if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]
            
            if not img_files:
                print(f"âš ï¸ è­¦å‘Š: ç±»åˆ« {class_name} ç›®å½•ä¸­æ²¡æœ‰å›¾ç‰‡æ–‡ä»¶")
                continue
                
            for img_name in img_files:
                self.images.append(os.path.join(class_dir, img_name))
                self.image_paths.append(os.path.join(class_dir, img_name))
                self.labels.append(self.class_to_idx[class_name])
        
        if len(self.images) == 0:
            print(f"âŒ é”™è¯¯: æ•°æ®é›†ç›®å½• {root_dir} ä¸­æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡")
    
    def __len__(self):
        return len(self.images)
    
    def __getitem__(self, idx):
        img_path = self.images[idx]
        label = self.labels[idx]
        
        # åŠ è½½å›¾ç‰‡
        try:
            image = Image.open(img_path).convert('RGB')
        except Exception as e:
            print(f"âŒ é”™è¯¯: æ— æ³•åŠ è½½å›¾ç‰‡ {img_path}: {e}")
            # è¿”å›ä¸€ä¸ªé»‘è‰²å›¾ç‰‡ä½œä¸ºå ä½ç¬¦
            image = Image.new('RGB', (224, 224), (0, 0, 0))
        
        if self.transform:
            image = self.transform(image)
        
        return image, label, img_path

def get_data_transforms():
    """è·å–æ•°æ®å¢å¼ºå’Œè½¬æ¢"""
    data_transforms = {
        'test': transforms.Compose([
            transforms.Resize((256, 256)),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
        ]),
    }
    return data_transforms

class EnhancedCataractModelEvaluator:
    """å¢å¼ºç‰ˆç™½å†…éšœæ¨¡å‹è¯„ä¼°å™¨"""
    
    def __init__(self, model_path=None):
        """åˆå§‹åŒ–è¯„ä¼°å™¨"""
        if model_path is None:
            base_dir = get_script_dir()
            model_path = os.path.join(base_dir, 'models/cataract_resnet18.pth')
        
        self.model_path = model_path
        self.device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        self.model = None
        self.classes = ['cataract', 'normal']
        
        # åˆ›å»ºç»“æœç›®å½•
        base_dir = get_script_dir()
        self.results_dir = os.path.join(base_dir, 'results')
        os.makedirs(self.results_dir, exist_ok=True)
        
        # åˆ›å»ºè¯¦ç»†å›¾è¡¨ç›®å½•
        self.charts_dir = os.path.join(self.results_dir, 'charts')
        os.makedirs(self.charts_dir, exist_ok=True)
        
        print(f"è„šæœ¬æ‰€åœ¨ç›®å½•: {base_dir}")
        print(f"æ¨¡å‹è·¯å¾„: {self.model_path}")
        print(f"ç»“æœç›®å½•: {self.results_dir}")
        print(f"å›¾è¡¨ç›®å½•: {self.charts_dir}")
    
    def load_model(self):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        print(f"åŠ è½½æ¨¡å‹: {self.model_path}")
        
        if not os.path.exists(self.model_path):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æ¨¡å‹æ–‡ä»¶ {self.model_path}")
            return False
        
        try:
            # æ„å»ºæ¨¡å‹ç»“æ„
            model = models.resnet18(pretrained=False)
            num_features = model.fc.in_features
            model.fc = nn.Sequential(
                nn.Dropout(0.5),
                nn.Linear(num_features, 512),
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(512, 2)
            )
            
            # åŠ è½½æƒé‡
            checkpoint = torch.load(self.model_path, map_location=self.device)
            model.load_state_dict(checkpoint['model_state_dict'])
            model = model.to(self.device)
            model.eval()
            
            self.model = model
            
            # å¦‚æœæœ‰ä¿å­˜çš„historyï¼Œå¯ä»¥ç”¨äºåˆ†æè®­ç»ƒè¿‡ç¨‹
            self.history = checkpoint.get('history', None)
            
            print(f"âœ… æ¨¡å‹åŠ è½½æˆåŠŸ")
            print(f"   ç±»åˆ«: {self.classes}")
            print(f"   è®¾å¤‡: {self.device}")
            
            return True
            
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            return False
    
    def create_test_dataloader(self):
        """åˆ›å»ºæµ‹è¯•æ•°æ®åŠ è½½å™¨"""
        print("\nå‡†å¤‡æµ‹è¯•æ•°æ®...")
        
        base_dir = get_script_dir()
        data_dir = os.path.join(base_dir, 'data')
        test_dir = os.path.join(data_dir, 'test')
        
        print(f"æ•°æ®ç›®å½•: {data_dir}")
        print(f"æµ‹è¯•æ•°æ®ç›®å½•: {test_dir}")
        
        if not os.path.exists(test_dir):
            print(f"âŒ é”™è¯¯: æ‰¾ä¸åˆ°æµ‹è¯•æ•°æ®ç›®å½• {test_dir}")
            return None, None
        
        data_transforms = get_data_transforms()
        test_dataset = CataractDataset(test_dir, transform=data_transforms['test'])
        
        if len(test_dataset) == 0:
            print("âŒ é”™è¯¯: æµ‹è¯•é›†ä¸ºç©º")
            return None, None
        
        num_workers = 0 if sys.platform == 'win32' else 2
        test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, num_workers=num_workers)
        
        print(f"æµ‹è¯•é›†: {len(test_dataset)} å¼ å›¾ç‰‡")
        return test_dataloader, test_dataset
    
    def evaluate_model_comprehensive(self):
        """å…¨é¢è¯„ä¼°æ¨¡å‹æ€§èƒ½"""
        if not self.model:
            print("âŒ é”™è¯¯: è¯·å…ˆåŠ è½½æ¨¡å‹")
            return
        
        test_dataloader, test_dataset = self.create_test_dataloader()
        if test_dataloader is None:
            return
        
        print("\nå¼€å§‹å…¨é¢è¯„ä¼°æ¨¡å‹...")
        
        all_preds = []
        all_labels = []
        all_probs = []
        all_paths = []
        
        self.model.eval()
        with torch.no_grad():
            for inputs, labels, paths in test_dataloader:
                inputs = inputs.to(self.device)
                outputs = self.model(inputs)
                probs = torch.nn.functional.softmax(outputs, dim=1)
                _, preds = torch.max(outputs, 1)
                
                all_preds.extend(preds.cpu().numpy())
                all_labels.extend(labels.numpy())
                all_probs.extend(probs.cpu().numpy())
                all_paths.extend(paths)
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        all_preds = np.array(all_preds)
        all_labels = np.array(all_labels)
        all_probs = np.array(all_probs)
        
        print(f"\nè¯„ä¼°æ•°æ®ç»Ÿè®¡:")
        print(f"æ€»æ ·æœ¬æ•°: {len(all_labels)}")
        print(f"ç™½å†…éšœæ ·æœ¬æ•°: {np.sum(all_labels == 1)}")
        print(f"æ­£å¸¸æ ·æœ¬æ•°: {np.sum(all_labels == 0)}")
        
        # æ‰§è¡Œå…¨é¢çš„è¯„ä¼°åˆ†æ
        self.comprehensive_analysis(all_labels, all_preds, all_probs, all_paths)
        
        return all_labels, all_preds, all_probs, all_paths
    
    def comprehensive_analysis(self, y_true, y_pred, y_probs, y_paths):
        """æ‰§è¡Œå…¨é¢çš„åˆ†æ"""
        print("\n" + "="*70)
        print("å…¨é¢æ¨¡å‹åˆ†æ")
        print("="*70)
        
        # å¯¼å…¥sklearnæ¨¡å—
        try:
            from sklearn.metrics import (confusion_matrix, classification_report, 
                                       roc_curve, auc, precision_recall_curve, 
                                       average_precision_score, f1_score, 
                                       precision_score, recall_score, accuracy_score)
        except ImportError:
            print("âŒ é”™è¯¯: ç¼ºå°‘ scikit-learn æ¨¡å—")
            print("è¯·è¿è¡Œ: pip install scikit-learn")
            return
        
        # 1. åŸºç¡€è¯„ä¼°æŒ‡æ ‡
        print("\n1. åŸºç¡€è¯„ä¼°æŒ‡æ ‡:")
        self.calculate_basic_metrics(y_true, y_pred)
        
        # 2. æ··æ·†çŸ©é˜µåˆ†æ
        print("\n2. æ··æ·†çŸ©é˜µåˆ†æ:")
        cm = confusion_matrix(y_true, y_pred)
        self.analyze_confusion_matrix(cm)
        
        # 3. ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨
        print("\n3. ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")
        self.generate_all_charts(y_true, y_pred, y_probs, y_paths)
        
        # 4. é”™è¯¯åˆ†æ
        print("\n4. é”™è¯¯åˆ†æ:")
        self.analyze_errors(y_true, y_pred, y_probs, y_paths)
        
        # 5. æ¨¡å‹ç½®ä¿¡åº¦åˆ†æ
        print("\n5. æ¨¡å‹ç½®ä¿¡åº¦åˆ†æ:")
        self.analyze_confidence(y_true, y_pred, y_probs)
        
        # 6. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        print("\n6. ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")
        self.generate_comprehensive_report(y_true, y_pred, y_probs, cm)
        
        print("\n" + "="*70)
        print("âœ… å…¨é¢è¯„ä¼°å®Œæˆ!")
        print("="*70)
    
    def calculate_basic_metrics(self, y_true, y_pred):
        """è®¡ç®—åŸºç¡€è¯„ä¼°æŒ‡æ ‡"""
        from sklearn.metrics import (accuracy_score, precision_score, 
                                   recall_score, f1_score, classification_report)
        
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='binary')
        recall = recall_score(y_true, y_pred, average='binary')
        f1 = f1_score(y_true, y_pred, average='binary')
        
        print(f"å‡†ç¡®ç‡ (Accuracy):           {accuracy:.4f} ({accuracy*100:.2f}%)")
        print(f"ç²¾ç¡®ç‡ (Precision):          {precision:.4f} ({precision*100:.2f}%)")
        print(f"å¬å›ç‡/æ•æ„Ÿåº¦ (Recall):      {recall:.4f} ({recall*100:.2f}%)")
        print(f"F1åˆ†æ•° (F1-Score):           {f1:.4f} ({f1*100:.2f}%)")
        
        print(f"\nåˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_true, y_pred, target_names=self.classes))
    
    def analyze_confusion_matrix(self, cm):
        """åˆ†ææ··æ·†çŸ©é˜µ"""
        if cm.shape == (1, 1):
            tn, fp, fn, tp = cm[0, 0], 0, 0, 0
        else:
            tn, fp, fn, tp = cm.ravel()
        
        total = tp + tn + fp + fn
        
        print(f"æ··æ·†çŸ©é˜µ:")
        print(f"          é¢„æµ‹æ­£å¸¸    é¢„æµ‹ç™½å†…éšœ")
        print(f"çœŸå®æ­£å¸¸   {tn:>6}        {fp:>6}")
        print(f"çœŸå®ç™½å†…éšœ {fn:>6}        {tp:>6}")
        print(f"\nè¯¦ç»†åˆ†æ:")
        print(f"æ€»æ ·æœ¬æ•°: {total}")
        print(f"çœŸé˜³æ€§ (TP): {tp} - æ­£ç¡®è¯†åˆ«çš„ç™½å†…éšœ")
        print(f"çœŸé˜´æ€§ (TN): {tn} - æ­£ç¡®è¯†åˆ«çš„æ­£å¸¸")
        print(f"å‡é˜³æ€§ (FP): {fp} - æ­£å¸¸è¯¯åˆ¤ä¸ºç™½å†…éšœ")
        print(f"å‡é˜´æ€§ (FN): {fn} - ç™½å†…éšœæ¼è¯Š")
        print(f"\né”™è¯¯ç‡åˆ†æ:")
        print(f"æ€»ä½“é”™è¯¯ç‡: {(fp+fn)/total*100:.2f}%" if total > 0 else "æ€»ä½“é”™è¯¯ç‡: N/A")
        print(f"å‡é˜³æ€§ç‡ (è¯¯æŠ¥ç‡): {fp/(fp+tn)*100:.2f}%" if (fp+tn) > 0 else "å‡é˜³æ€§ç‡: N/A")
        print(f"å‡é˜´æ€§ç‡ (æ¼æŠ¥ç‡): {fn/(fn+tp)*100:.2f}%" if (fn+tp) > 0 else "å‡é˜´æ€§ç‡: N/A")
    
    def generate_all_charts(self, y_true, y_pred, y_probs, y_paths):
        """ç”Ÿæˆæ‰€æœ‰å¯è§†åŒ–å›¾è¡¨"""
        
        # 1. æ··æ·†çŸ©é˜µçƒ­å›¾
        self.plot_confusion_matrix(y_true, y_pred)
        
        # 2. ROCæ›²çº¿
        self.plot_roc_curve(y_true, y_probs)
        
        # 3. ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿
        self.plot_precision_recall_curve(y_true, y_probs)
        
        # 4. é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ
        self.plot_prediction_distribution(y_true, y_probs)
        
        # 5. æ¨¡å‹æ€§èƒ½æŒ‡æ ‡å¯¹æ¯” - ä¿®å¤äº†æ•°ç»„å½¢çŠ¶é—®é¢˜
        self.plot_metrics_comparison_fixed(y_true, y_pred)
        
        # 6. ç½®ä¿¡åº¦åˆ†å¸ƒ
        self.plot_confidence_distribution(y_true, y_pred, y_probs)
        
        # 7. é˜ˆå€¼åˆ†æ
        self.plot_threshold_analysis(y_true, y_probs)
        
        # 8. è®­ç»ƒå†å²ï¼ˆå¦‚æœæœ‰ï¼‰
        if hasattr(self, 'history') and self.history:
            self.plot_training_history()
        
        # 9. é”™è¯¯åˆ†ç±»æ ·æœ¬å±•ç¤º
        self.plot_misclassified_samples(y_true, y_pred, y_probs, y_paths, num_samples=12)
        
        # 10. æ€§èƒ½å¯¹æ¯”çŸ©é˜µ - ä¿®å¤äº†æ•°ç»„å½¢çŠ¶é—®é¢˜
        self.plot_performance_matrix_fixed(y_true, y_pred, y_probs)
    
    def plot_confusion_matrix(self, y_true, y_pred):
        """ç»˜åˆ¶æ··æ·†çŸ©é˜µ"""
        from sklearn.metrics import confusion_matrix
        
        cm = confusion_matrix(y_true, y_pred)
        
        plt.figure(figsize=(10, 8))
        
        # å°è¯•ä½¿ç”¨seaborn
        try:
            import seaborn as sns
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=self.classes, yticklabels=self.classes,
                       cbar_kws={'label': 'æ ·æœ¬æ•°é‡'})
            plt.title('æ··æ·†çŸ©é˜µ - ç™½å†…éšœç­›æŸ¥æ¨¡å‹', fontsize=16, fontweight='bold')
        except ImportError:
            # ä½¿ç”¨matplotlibç»˜åˆ¶
            plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
            plt.title('æ··æ·†çŸ©é˜µ', fontsize=16, fontweight='bold')
            plt.colorbar(label='æ ·æœ¬æ•°é‡')
            
            # æ·»åŠ æ–‡æœ¬æ ‡ç­¾
            thresh = cm.max() / 2.
            for i in range(cm.shape[0]):
                for j in range(cm.shape[1]):
                    plt.text(j, i, format(cm[i, j], 'd'),
                            ha="center", va="center",
                            color="white" if cm[i, j] > thresh else "black")
            
            plt.xticks(range(len(self.classes)), self.classes)
            plt.yticks(range(len(self.classes)), self.classes)
        
        plt.ylabel('çœŸå®æ ‡ç­¾', fontsize=12)
        plt.xlabel('é¢„æµ‹æ ‡ç­¾', fontsize=12)
        plt.tight_layout()
        
        save_path = os.path.join(self.charts_dir, '01_æ··æ·†çŸ©é˜µ.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ··æ·†çŸ©é˜µå›¾å·²ä¿å­˜: {save_path}")
    
    def plot_roc_curve(self, y_true, y_probs):
        """ç»˜åˆ¶ROCæ›²çº¿"""
        from sklearn.metrics import roc_curve, auc
        
        if len(np.unique(y_true)) > 1:
            fpr, tpr, thresholds = roc_curve(y_true, y_probs[:, 1])
            roc_auc = auc(fpr, tpr)
            
            # æ‰¾åˆ°æœ€ä½³é˜ˆå€¼ï¼ˆæœ€é è¿‘å·¦ä¸Šè§’çš„ç‚¹ï¼‰
            optimal_idx = np.argmax(tpr - fpr)
            optimal_threshold = thresholds[optimal_idx]
            
            plt.figure(figsize=(10, 8))
            plt.plot(fpr, tpr, color='darkorange', lw=2, 
                    label=f'ROCæ›²çº¿ (AUC = {roc_auc:.3f})')
            plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='éšæœºåˆ†ç±»å™¨')
            
            # æ ‡è®°æœ€ä½³é˜ˆå€¼ç‚¹
            plt.scatter(fpr[optimal_idx], tpr[optimal_idx], 
                       color='red', s=100, zorder=5, 
                       label=f'æœ€ä½³é˜ˆå€¼={optimal_threshold:.3f}')
            
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('å‡é˜³æ€§ç‡ (1-ç‰¹å¼‚åº¦)', fontsize=12)
            plt.ylabel('çœŸé˜³æ€§ç‡ (æ•æ„Ÿåº¦)', fontsize=12)
            plt.title('ROCæ›²çº¿ - æ¨¡å‹åŒºåˆ†èƒ½åŠ›', fontsize=16, fontweight='bold')
            plt.legend(loc="lower right")
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            
            save_path = os.path.join(self.charts_dir, '02_ROCæ›²çº¿.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"âœ… ROCæ›²çº¿å·²ä¿å­˜: {save_path}")
        else:
            print("âš ï¸ åªæœ‰ä¸€ç±»æ•°æ®ï¼Œæ— æ³•ç»˜åˆ¶ROCæ›²çº¿")
    
    def plot_precision_recall_curve(self, y_true, y_probs):
        """ç»˜åˆ¶ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿"""
        from sklearn.metrics import precision_recall_curve, average_precision_score
        
        if len(np.unique(y_true)) > 1:
            precision, recall, thresholds = precision_recall_curve(y_true, y_probs[:, 1])
            avg_precision = average_precision_score(y_true, y_probs[:, 1])
            
            plt.figure(figsize=(10, 8))
            plt.plot(recall, precision, color='green', lw=2, 
                    label=f'PRæ›²çº¿ (AP = {avg_precision:.3f})')
            
            plt.xlim([0.0, 1.0])
            plt.ylim([0.0, 1.05])
            plt.xlabel('å¬å›ç‡ (Recall)', fontsize=12)
            plt.ylabel('ç²¾ç¡®ç‡ (Precision)', fontsize=12)
            plt.title('ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿ - æ¨¡å‹ç²¾ç¡®æ€§', fontsize=16, fontweight='bold')
            plt.legend(loc="upper right")
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            
            save_path = os.path.join(self.charts_dir, '03_ç²¾ç¡®ç‡å¬å›ç‡æ›²çº¿.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"âœ… ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿å·²ä¿å­˜: {save_path}")
    
    def plot_prediction_distribution(self, y_true, y_probs):
        """ç»˜åˆ¶é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ"""
        plt.figure(figsize=(14, 6))
        
        # å­å›¾1: æ¦‚ç‡åˆ†å¸ƒç›´æ–¹å›¾
        plt.subplot(1, 2, 1)
        
        if len(y_probs.shape) > 1 and y_probs.shape[1] > 1:
            cataract_probs = y_probs[y_true == 1, 1] if 1 in y_true else []
            normal_probs = y_probs[y_true == 0, 1] if 0 in y_true else []
            
            if len(cataract_probs) > 0:
                plt.hist(cataract_probs, bins=30, alpha=0.7, color='red', 
                        label='ç™½å†…éšœ', density=True)
            if len(normal_probs) > 0:
                plt.hist(normal_probs, bins=30, alpha=0.7, color='blue', 
                        label='æ­£å¸¸', density=True)
            
            plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='é˜ˆå€¼=0.5')
        
        plt.xlabel('é¢„æµ‹ä¸ºç™½å†…éšœçš„æ¦‚ç‡', fontsize=12)
        plt.ylabel('å¯†åº¦', fontsize=12)
        plt.title('é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        if len(cataract_probs) > 0 or len(normal_probs) > 0:
            plt.legend()
        plt.grid(True, alpha=0.3)
        
        # å­å›¾2: æ ¸å¯†åº¦ä¼°è®¡
        plt.subplot(1, 2, 2)
        
        if len(y_probs.shape) > 1 and y_probs.shape[1] > 1:
            try:
                import seaborn as sns
                if len(cataract_probs) > 0:
                    sns.kdeplot(cataract_probs, color='red', label='ç™½å†…éšœ', fill=True, alpha=0.5)
                if len(normal_probs) > 0:
                    sns.kdeplot(normal_probs, color='blue', label='æ­£å¸¸', fill=True, alpha=0.5)
                plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='é˜ˆå€¼=0.5')
            except ImportError:
                # å¦‚æœæ²¡æœ‰seabornï¼Œä½¿ç”¨ç›´æ–¹å›¾
                if len(cataract_probs) > 0:
                    plt.hist(cataract_probs, bins=30, alpha=0.5, color='red', 
                            label='ç™½å†…éšœ', density=True, histtype='stepfilled')
                if len(normal_probs) > 0:
                    plt.hist(normal_probs, bins=30, alpha=0.5, color='blue', 
                            label='æ­£å¸¸', density=True, histtype='stepfilled')
                plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='é˜ˆå€¼=0.5')
        
        plt.xlabel('é¢„æµ‹ä¸ºç™½å†…éšœçš„æ¦‚ç‡', fontsize=12)
        plt.ylabel('å¯†åº¦', fontsize=12)
        plt.title('æ¦‚ç‡å¯†åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
        if len(cataract_probs) > 0 or len(normal_probs) > 0:
            plt.legend()
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        save_path = os.path.join(self.charts_dir, '04_é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")
    
    def plot_metrics_comparison_fixed(self, y_true, y_pred):
        """ç»˜åˆ¶æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”å›¾ - ä¿®å¤ç‰ˆ"""
        from sklearn.metrics import (accuracy_score, precision_score, 
                                   recall_score, f1_score)
        
        # è®¡ç®—å„é¡¹æŒ‡æ ‡
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='binary')
        recall = recall_score(y_true, y_pred, average='binary')
        f1 = f1_score(y_true, y_pred, average='binary')
        
        # è®¡ç®—ç±»åˆ«ç‰¹å®šçš„æŒ‡æ ‡
        precision_cataract = precision_score(y_true, y_pred, pos_label=1)
        recall_cataract = recall_score(y_true, y_pred, pos_label=1)
        
        # å¯¹äºæ­£å¸¸ç±»åˆ«ï¼ˆéœ€è¦åè½¬æ ‡ç­¾ï¼‰
        y_pred_normal = 1 - y_pred
        y_true_normal = 1 - y_true
        precision_normal = precision_score(y_true_normal, y_pred_normal, pos_label=1) if len(np.unique(y_true_normal)) > 1 else 0
        recall_normal = recall_score(y_true_normal, y_pred_normal, pos_label=1) if len(np.unique(y_true_normal)) > 1 else 0
        
        metrics_labels = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'F1åˆ†æ•°']
        
        # åˆ›å»ºæ•°æ®æ•°ç»„ï¼Œç¡®ä¿é•¿åº¦ä¸€è‡´
        overall_data = [accuracy, precision, recall, f1]
        cataract_data = [np.nan, precision_cataract, recall_cataract, np.nan]
        normal_data = [np.nan, precision_normal, recall_normal, np.nan]
        
        fig, axes = plt.subplots(1, 3, figsize=(18, 6))
        
        # å­å›¾1: æ€»ä½“æŒ‡æ ‡é›·è¾¾å›¾
        ax1 = axes[0]
        angles = np.linspace(0, 2 * np.pi, len(metrics_labels), endpoint=False).tolist()
        
        # é›·è¾¾å›¾éœ€è¦é—­åˆï¼Œæ‰€ä»¥å¤åˆ¶ç¬¬ä¸€ä¸ªå€¼åˆ°æœ«å°¾
        overall_metrics_radar = overall_data + [overall_data[0]]
        angles_radar = angles + [angles[0]]
        
        ax1.plot(angles_radar, overall_metrics_radar, 'o-', linewidth=2, label='æ€»ä½“æŒ‡æ ‡')
        ax1.fill(angles_radar, overall_metrics_radar, alpha=0.25)
        ax1.set_xticks(angles)
        ax1.set_xticklabels(metrics_labels)
        ax1.set_ylim(0, 1)
        ax1.set_title('æ€»ä½“æŒ‡æ ‡é›·è¾¾å›¾', fontsize=14, fontweight='bold')
        ax1.grid(True)
        
        # å­å›¾2: æŸ±çŠ¶å›¾å¯¹æ¯”
        ax2 = axes[1]
        x = np.arange(len(metrics_labels))
        width = 0.25
        
        # ä¿®å¤ï¼šç¡®ä¿æ¯ä¸ªbarçš„æ•°æ®é•¿åº¦ä¸xä¸€è‡´
        ax2.bar(x - width, overall_data, width, label='æ€»ä½“', color='blue', alpha=0.7)
        ax2.bar(x, cataract_data, width, label='ç™½å†…éšœ', color='red', alpha=0.7)
        ax2.bar(x + width, normal_data, width, label='æ­£å¸¸', color='green', alpha=0.7)
        
        ax2.set_xticks(x)
        ax2.set_xticklabels(metrics_labels)
        ax2.set_ylim(0, 1)
        ax2.set_ylabel('åˆ†æ•°', fontsize=12)
        ax2.set_title('å„ç±»åˆ«æŒ‡æ ‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, val in enumerate(overall_data):
            if not np.isnan(val):
                ax2.text(i - width, val + 0.01, f'{val:.2%}', ha='center', va='bottom', fontsize=8)
        
        for i, val in enumerate(cataract_data):
            if not np.isnan(val):
                ax2.text(i, val + 0.01, f'{val:.2%}', ha='center', va='bottom', fontsize=8)
        
        for i, val in enumerate(normal_data):
            if not np.isnan(val):
                ax2.text(i + width, val + 0.01, f'{val:.2%}', ha='center', va='bottom', fontsize=8)
        
        # å­å›¾3: çƒ­åŠ›å›¾
        ax3 = axes[2]
        heatmap_data = np.array([overall_data, cataract_data, normal_data])
        
        im = ax3.imshow(heatmap_data, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)
        ax3.set_xticks(range(len(metrics_labels)))
        ax3.set_xticklabels(metrics_labels, rotation=45)
        ax3.set_yticks(range(3))
        ax3.set_yticklabels(['æ€»ä½“', 'ç™½å†…éšœ', 'æ­£å¸¸'])
        ax3.set_title('æŒ‡æ ‡çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i in range(heatmap_data.shape[0]):
            for j in range(heatmap_data.shape[1]):
                if not np.isnan(heatmap_data[i, j]):
                    ax3.text(j, i, f'{heatmap_data[i, j]:.2%}', 
                            ha="center", va="center", color="black", fontsize=10)
        
        plt.colorbar(im, ax=ax3, label='åˆ†æ•°')
        
        plt.tight_layout()
        save_path = os.path.join(self.charts_dir, '05_æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”å›¾å·²ä¿å­˜: {save_path}")
    
    def plot_confidence_distribution(self, y_true, y_pred, y_probs):
        """ç»˜åˆ¶ç½®ä¿¡åº¦åˆ†å¸ƒ"""
        if len(y_probs.shape) > 1 and y_probs.shape[1] > 1:
            # è·å–é¢„æµ‹ç½®ä¿¡åº¦
            pred_confidences = np.max(y_probs, axis=1)
            
            # åŒºåˆ†æ­£ç¡®å’Œé”™è¯¯é¢„æµ‹
            correct_mask = (y_pred == y_true)
            incorrect_mask = (y_pred != y_true)
            
            correct_confidences = pred_confidences[correct_mask]
            incorrect_confidences = pred_confidences[incorrect_mask]
            
            plt.figure(figsize=(14, 6))
            
            # å­å›¾1: ç½®ä¿¡åº¦åˆ†å¸ƒç›´æ–¹å›¾
            plt.subplot(1, 2, 1)
            
            if len(correct_confidences) > 0:
                plt.hist(correct_confidences, bins=20, alpha=0.7, color='green', 
                        label=f'æ­£ç¡®é¢„æµ‹ ({len(correct_confidences)})', density=True)
            
            if len(incorrect_confidences) > 0:
                plt.hist(incorrect_confidences, bins=20, alpha=0.7, color='red', 
                        label=f'é”™è¯¯é¢„æµ‹ ({len(incorrect_confidences)})', density=True)
            
            plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='é˜ˆå€¼=0.5')
            plt.xlabel('æ¨¡å‹ç½®ä¿¡åº¦', fontsize=12)
            plt.ylabel('å¯†åº¦', fontsize=12)
            plt.title('é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ', fontsize=14, fontweight='bold')
            plt.legend()
            plt.grid(True, alpha=0.3)
            
            # å­å›¾2: ç®±çº¿å›¾å¯¹æ¯”
            plt.subplot(1, 2, 2)
            
            data_to_plot = []
            labels = []
            
            if len(correct_confidences) > 0:
                data_to_plot.append(correct_confidences)
                labels.append(f'æ­£ç¡®é¢„æµ‹\n(n={len(correct_confidences)})')
            
            if len(incorrect_confidences) > 0:
                data_to_plot.append(incorrect_confidences)
                labels.append(f'é”™è¯¯é¢„æµ‹\n(n={len(incorrect_confidences)})')
            
            if data_to_plot:
                box = plt.boxplot(data_to_plot, labels=labels, patch_artist=True)
                
                # è®¾ç½®é¢œè‰²
                colors = ['lightgreen', 'lightcoral']
                for patch, color in zip(box['boxes'], colors[:len(data_to_plot)]):
                    patch.set_facecolor(color)
                
                # æ·»åŠ å‡å€¼ç‚¹
                for i, data in enumerate(data_to_plot):
                    mean_val = np.mean(data)
                    plt.scatter(i+1, mean_val, color='blue', s=100, zorder=3, label='å‡å€¼' if i == 0 else "")
            
            plt.ylabel('æ¨¡å‹ç½®ä¿¡åº¦', fontsize=12)
            plt.title('ç½®ä¿¡åº¦ç»Ÿè®¡å¯¹æ¯”', fontsize=14, fontweight='bold')
            plt.grid(True, alpha=0.3, axis='y')
            if len(data_to_plot) > 0:
                plt.legend()
            
            plt.tight_layout()
            save_path = os.path.join(self.charts_dir, '06_ç½®ä¿¡åº¦åˆ†å¸ƒ.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"âœ… ç½®ä¿¡åº¦åˆ†å¸ƒå›¾å·²ä¿å­˜: {save_path}")
    
    def plot_threshold_analysis(self, y_true, y_probs):
        """ç»˜åˆ¶é˜ˆå€¼åˆ†æå›¾"""
        if len(np.unique(y_true)) > 1 and len(y_probs.shape) > 1:
            from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
            
            thresholds = np.linspace(0, 1, 101)
            accuracies = []
            precisions = []
            recalls = []
            f1_scores = []
            
            for threshold in thresholds:
                # æ ¹æ®é˜ˆå€¼é‡æ–°åˆ†ç±»
                y_pred_thresh = (y_probs[:, 1] >= threshold).astype(int)
                
                # è®¡ç®—æŒ‡æ ‡
                accuracies.append(accuracy_score(y_true, y_pred_thresh))
                precisions.append(precision_score(y_true, y_pred_thresh, zero_division=0))
                recalls.append(recall_score(y_true, y_pred_thresh, zero_division=0))
                f1_scores.append(f1_score(y_true, y_pred_thresh, zero_division=0))
            
            plt.figure(figsize=(12, 8))
            
            plt.plot(thresholds, accuracies, label='å‡†ç¡®ç‡', linewidth=2)
            plt.plot(thresholds, precisions, label='ç²¾ç¡®ç‡', linewidth=2)
            plt.plot(thresholds, recalls, label='å¬å›ç‡', linewidth=2)
            plt.plot(thresholds, f1_scores, label='F1åˆ†æ•°', linewidth=2)
            
            # æ ‡è®°é»˜è®¤é˜ˆå€¼0.5
            plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.5, label='é»˜è®¤é˜ˆå€¼=0.5')
            
            # æ‰¾åˆ°æœ€ä½³F1åˆ†æ•°å¯¹åº”çš„é˜ˆå€¼
            best_f1_idx = np.argmax(f1_scores)
            best_threshold = thresholds[best_f1_idx]
            plt.axvline(x=best_threshold, color='red', linestyle=':', 
                       alpha=0.7, label=f'æœ€ä½³F1é˜ˆå€¼={best_threshold:.2f}')
            
            plt.xlabel('åˆ†ç±»é˜ˆå€¼', fontsize=12)
            plt.ylabel('æŒ‡æ ‡åˆ†æ•°', fontsize=12)
            plt.title('é˜ˆå€¼å¯¹æ¨¡å‹æ€§èƒ½çš„å½±å“', fontsize=16, fontweight='bold')
            plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))
            plt.grid(True, alpha=0.3)
            plt.xlim([0, 1])
            plt.ylim([0, 1])
            
            plt.tight_layout()
            save_path = os.path.join(self.charts_dir, '07_é˜ˆå€¼åˆ†æ.png')
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            plt.close()
            print(f"âœ… é˜ˆå€¼åˆ†æå›¾å·²ä¿å­˜: {save_path}")
            
            # è¾“å‡ºæœ€ä½³é˜ˆå€¼å»ºè®®
            print(f"\nğŸ“Š é˜ˆå€¼åˆ†æç»“æœ:")
            print(f"  é»˜è®¤é˜ˆå€¼(0.5): F1åˆ†æ•° = {f1_scores[50]:.4f}")
            print(f"  æœ€ä½³é˜ˆå€¼({best_threshold:.3f}): F1åˆ†æ•° = {f1_scores[best_f1_idx]:.4f}")
            print(f"  æå‡: {(f1_scores[best_f1_idx] - f1_scores[50])*100:.2f}%")
    
    def plot_training_history(self):
        """ç»˜åˆ¶è®­ç»ƒå†å²ï¼ˆå¦‚æœå¯ç”¨ï¼‰"""
        if hasattr(self, 'history') and self.history:
            history = self.history
            
            if 'train_loss' in history and 'val_loss' in history:
                plt.figure(figsize=(14, 6))
                
                # å­å›¾1: æŸå¤±æ›²çº¿
                plt.subplot(1, 2, 1)
                epochs = range(1, len(history['train_loss']) + 1)
                
                plt.plot(epochs, history['train_loss'], 'b-', label='è®­ç»ƒæŸå¤±', linewidth=2)
                plt.plot(epochs, history['val_loss'], 'r-', label='éªŒè¯æŸå¤±', linewidth=2)
                plt.title('è®­ç»ƒå’ŒéªŒè¯æŸå¤±', fontsize=14, fontweight='bold')
                plt.xlabel('è®­ç»ƒè½®æ¬¡ (Epoch)', fontsize=12)
                plt.ylabel('æŸå¤±å€¼', fontsize=12)
                plt.legend()
                plt.grid(True, alpha=0.3)
                
                # å­å›¾2: å‡†ç¡®ç‡æ›²çº¿
                plt.subplot(1, 2, 2)
                
                plt.plot(epochs, history['train_acc'], 'b-', label='è®­ç»ƒå‡†ç¡®ç‡', linewidth=2)
                plt.plot(epochs, history['val_acc'], 'r-', label='éªŒè¯å‡†ç¡®ç‡', linewidth=2)
                plt.title('è®­ç»ƒå’ŒéªŒè¯å‡†ç¡®ç‡', fontsize=14, fontweight='bold')
                plt.xlabel('è®­ç»ƒè½®æ¬¡ (Epoch)', fontsize=12)
                plt.ylabel('å‡†ç¡®ç‡', fontsize=12)
                plt.legend()
                plt.grid(True, alpha=0.3)
                
                plt.tight_layout()
                save_path = os.path.join(self.charts_dir, '08_è®­ç»ƒå†å².png')
                plt.savefig(save_path, dpi=150, bbox_inches='tight')
                plt.close()
                print(f"âœ… è®­ç»ƒå†å²å›¾å·²ä¿å­˜: {save_path}")
    
    def plot_misclassified_samples(self, y_true, y_pred, y_probs, y_paths, num_samples=12):
        """ç»˜åˆ¶é”™è¯¯åˆ†ç±»æ ·æœ¬ç¤ºä¾‹"""
        # æ‰¾å‡ºé”™è¯¯åˆ†ç±»çš„æ ·æœ¬
        misclassified_indices = np.where(y_pred != y_true)[0]
        
        if len(misclassified_indices) == 0:
            print("âš ï¸ æ²¡æœ‰é”™è¯¯åˆ†ç±»çš„æ ·æœ¬å¯å±•ç¤º")
            return
        
        # éšæœºé€‰æ‹©ä¸€äº›æ ·æœ¬
        if len(misclassified_indices) > num_samples:
            selected_indices = np.random.choice(misclassified_indices, num_samples, replace=False)
        else:
            selected_indices = misclassified_indices
        
        # åˆ›å»ºå­å›¾
        num_rows = int(np.ceil(len(selected_indices) / 4))
        fig, axes = plt.subplots(num_rows, 4, figsize=(16, 4*num_rows))
        
        if num_rows == 1:
            axes = axes.reshape(1, -1)
        
        for idx, (ax, sample_idx) in enumerate(zip(axes.flatten(), selected_indices)):
            if idx >= len(selected_indices):
                ax.axis('off')
                continue
            
            try:
                # åŠ è½½å›¾ç‰‡
                img_path = y_paths[sample_idx]
                img = Image.open(img_path).convert('RGB')
                img_resized = img.resize((150, 150))
                
                # æ˜¾ç¤ºå›¾ç‰‡
                ax.imshow(img_resized)
                
                # æ·»åŠ æ ‡é¢˜ä¿¡æ¯
                true_label = self.classes[y_true[sample_idx]]
                pred_label = self.classes[y_pred[sample_idx]]
                confidence = np.max(y_probs[sample_idx])
                
                title_color = 'red'  # é”™è¯¯åˆ†ç±»ç”¨çº¢è‰²
                ax.set_title(f"çœŸå®: {true_label}\né¢„æµ‹: {pred_label}\nç½®ä¿¡åº¦: {confidence:.3f}", 
                           color=title_color, fontsize=9)
                ax.axis('off')
                
            except Exception as e:
                ax.text(0.5, 0.5, f"æ— æ³•åŠ è½½å›¾ç‰‡\n{str(e)[:30]}...", 
                       ha='center', va='center', fontsize=8)
                ax.axis('off')
        
        plt.suptitle('é”™è¯¯åˆ†ç±»æ ·æœ¬ç¤ºä¾‹', fontsize=16, fontweight='bold', y=1.02)
        plt.tight_layout()
        
        save_path = os.path.join(self.charts_dir, '09_é”™è¯¯åˆ†ç±»æ ·æœ¬.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… é”™è¯¯åˆ†ç±»æ ·æœ¬å›¾å·²ä¿å­˜: {save_path}")
    
    def plot_performance_matrix_fixed(self, y_true, y_pred, y_probs):
        """ç»˜åˆ¶æ€§èƒ½å¯¹æ¯”çŸ©é˜µ - ä¿®å¤ç‰ˆ"""
        from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
        
        cm = confusion_matrix(y_true, y_pred)
        
        if cm.shape == (1, 1):
            tn, fp, fn, tp = cm[0, 0], 0, 0, 0
        else:
            tn, fp, fn, tp = cm.ravel()
        
        # è®¡ç®—å„ç§æ€§èƒ½æŒ‡æ ‡
        total = tp + tn + fp + fn
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='binary')
        recall = recall_score(y_true, y_pred, average='binary')
        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
        f1 = f1_score(y_true, y_pred, average='binary')
        
        # åˆ›å»ºæ€§èƒ½çŸ©é˜µ - ç¡®ä¿å½¢çŠ¶æ­£ç¡®
        performance_matrix = np.array([
            [accuracy, precision, recall, specificity, f1],
            [tp/total if total > 0 else 0, fp/total if total > 0 else 0, 
             fn/total if total > 0 else 0, tn/total if total > 0 else 0, 
             (fp+fn)/total if total > 0 else 0]
        ])
        
        fig, axes = plt.subplots(2, 2, figsize=(14, 12))
        
        # å­å›¾1: æ€§èƒ½æŒ‡æ ‡é›·è¾¾å›¾
        ax1 = axes[0, 0]
        metrics = ['å‡†ç¡®ç‡', 'ç²¾ç¡®ç‡', 'å¬å›ç‡', 'ç‰¹å¼‚åº¦', 'F1åˆ†æ•°']
        values = [accuracy, precision, recall, specificity, f1]
        
        angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False).tolist()
        values_radar = values + [values[0]]  # é—­åˆé›·è¾¾å›¾
        angles_radar = angles + [angles[0]]
        
        ax1.plot(angles_radar, values_radar, 'o-', linewidth=2)
        ax1.fill(angles_radar, values_radar, alpha=0.25)
        ax1.set_xticks(angles)
        ax1.set_xticklabels(metrics)
        ax1.set_ylim(0, 1)
        ax1.set_title('æ€§èƒ½æŒ‡æ ‡é›·è¾¾å›¾', fontsize=14, fontweight='bold')
        ax1.grid(True)
        
        # å­å›¾2: é”™è¯¯ç±»å‹åˆ†å¸ƒ
        ax2 = axes[0, 1]
        error_labels = ['çœŸé˜³æ€§', 'å‡é˜³æ€§', 'å‡é˜´æ€§', 'çœŸé˜´æ€§', 'æ€»é”™è¯¯']
        error_values = [tp, fp, fn, tn, fp+fn]
        error_colors = ['green', 'orange', 'red', 'blue', 'purple']
        
        ax2.bar(error_labels, error_values, color=error_colors, alpha=0.7)
        ax2.set_title('é¢„æµ‹ç»“æœåˆ†å¸ƒ', fontsize=14, fontweight='bold')
        ax2.set_ylabel('æ ·æœ¬æ•°é‡', fontsize=12)
        ax2.grid(True, alpha=0.3, axis='y')
        
        # åœ¨æŸ±å­ä¸Šæ·»åŠ æ•°å€¼æ ‡ç­¾
        for i, v in enumerate(error_values):
            ax2.text(i, v + 0.5, str(v), ha='center', va='bottom', fontsize=10)
        
        # å­å›¾3: æ€§èƒ½æŒ‡æ ‡çƒ­åŠ›å›¾
        ax3 = axes[1, 0]
        im = ax3.imshow(performance_matrix, cmap='YlOrRd', aspect='auto', vmin=0, vmax=1)
        
        ax3.set_xticks(range(len(metrics)))
        ax3.set_xticklabels(metrics, rotation=45)
        ax3.set_yticks(range(2))
        ax3.set_yticklabels(['æŒ‡æ ‡å€¼', 'æ ·æœ¬æ¯”ä¾‹'])
        ax3.set_title('æ€§èƒ½æŒ‡æ ‡çƒ­åŠ›å›¾', fontsize=14, fontweight='bold')
        
        # æ·»åŠ æ•°å€¼æ ‡ç­¾
        for i in range(performance_matrix.shape[0]):
            for j in range(performance_matrix.shape[1]):
                ax3.text(j, i, f'{performance_matrix[i, j]:.3f}',
                        ha="center", va="center", color="black", fontsize=9)
        
        plt.colorbar(im, ax=ax3, label='åˆ†æ•°')
        
        # å­å›¾4: æ¨¡å‹è¡¨ç°æ€»ç»“
        ax4 = axes[1, 1]
        ax4.axis('off')
        
        summary_text = f"""æ¨¡å‹æ€§èƒ½æ€»ç»“:
{'='*30}
æ€»æ ·æœ¬æ•°: {total}
æ­£ç¡®é¢„æµ‹: {tp + tn} ({accuracy*100:.2f}%)
é”™è¯¯é¢„æµ‹: {fp + fn} ({(fp+fn)/total*100:.2f}% if total > 0 else 0)

è¯¦ç»†æŒ‡æ ‡:
å‡†ç¡®ç‡: {accuracy:.4f} ({accuracy*100:.2f}%)
ç²¾ç¡®ç‡: {precision:.4f} ({precision*100:.2f}%)
å¬å›ç‡: {recall:.4f} ({recall*100:.2f}%)
ç‰¹å¼‚åº¦: {specificity:.4f} ({specificity*100:.2f}%)
F1åˆ†æ•°: {f1:.4f} ({f1*100:.2f}%)

åˆ†ç±»ç»“æœ:
çœŸé˜³æ€§(TP): {tp} (æ­£ç¡®è¯†åˆ«çš„ç™½å†…éšœ)
çœŸé˜´æ€§(TN): {tn} (æ­£ç¡®è¯†åˆ«çš„æ­£å¸¸)
å‡é˜³æ€§(FP): {fp} (æ­£å¸¸è¯¯åˆ¤ä¸ºç™½å†…éšœ)
å‡é˜´æ€§(FN): {fn} (ç™½å†…éšœæ¼è¯Š)
"""
        
        ax4.text(0.1, 0.5, summary_text, fontsize=10, fontfamily='monospace',
                verticalalignment='center', horizontalalignment='left',
                bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))
        ax4.set_title('æ¨¡å‹è¡¨ç°æ€»ç»“', fontsize=14, fontweight='bold')
        
        plt.tight_layout()
        save_path = os.path.join(self.charts_dir, '10_æ€§èƒ½å¯¹æ¯”çŸ©é˜µ.png')
        plt.savefig(save_path, dpi=150, bbox_inches='tight')
        plt.close()
        print(f"âœ… æ€§èƒ½å¯¹æ¯”çŸ©é˜µå›¾å·²ä¿å­˜: {save_path}")
    
    def analyze_errors(self, y_true, y_pred, y_probs, y_paths):
        """åˆ†æé”™è¯¯åˆ†ç±»"""
        # æ‰¾å‡ºé”™è¯¯åˆ†ç±»çš„æ ·æœ¬
        error_indices = np.where(y_pred != y_true)[0]
        
        if len(error_indices) == 0:
            print("âœ… æ²¡æœ‰é”™è¯¯åˆ†ç±»çš„æ ·æœ¬")
            return
        
        print(f"\né”™è¯¯åˆ†æ:")
        print(f"æ€»é”™è¯¯æ•°: {len(error_indices)}")
        print(f"é”™è¯¯ç‡: {len(error_indices)/len(y_true)*100:.2f}%")
        
        # åˆ†æé”™è¯¯ç±»å‹
        false_positives = []
        false_negatives = []
        
        for idx in error_indices:
            if y_true[idx] == 0 and y_pred[idx] == 1:  # æ­£å¸¸è¢«è¯¯åˆ¤ä¸ºç™½å†…éšœ
                false_positives.append(idx)
            elif y_true[idx] == 1 and y_pred[idx] == 0:  # ç™½å†…éšœè¢«æ¼è¯Š
                false_negatives.append(idx)
        
        print(f"å‡é˜³æ€§ (FP, æ­£å¸¸è¯¯åˆ¤): {len(false_positives)}")
        print(f"å‡é˜´æ€§ (FN, ç™½å†…éšœæ¼è¯Š): {len(false_negatives)}")
        
        # åˆ†æé”™è¯¯æ ·æœ¬çš„ç½®ä¿¡åº¦
        if len(error_indices) > 0 and len(y_probs.shape) > 1:
            error_confidences = np.max(y_probs[error_indices], axis=1)
            print(f"é”™è¯¯æ ·æœ¬å¹³å‡ç½®ä¿¡åº¦: {np.mean(error_confidences):.3f}")
            print(f"é”™è¯¯æ ·æœ¬ç½®ä¿¡åº¦èŒƒå›´: [{np.min(error_confidences):.3f}, {np.max(error_confidences):.3f}]")
            
            # ç»Ÿè®¡ä½ç½®ä¿¡åº¦é”™è¯¯
            low_confidence_errors = np.sum(error_confidences < 0.7)
            print(f"ä½ç½®ä¿¡åº¦é”™è¯¯ (<0.7): {low_confidence_errors}")
    
    def analyze_confidence(self, y_true, y_pred, y_probs):
        """åˆ†ææ¨¡å‹ç½®ä¿¡åº¦"""
        if len(y_probs.shape) > 1:
            # è·å–é¢„æµ‹ç½®ä¿¡åº¦
            pred_confidences = np.max(y_probs, axis=1)
            
            print(f"\nç½®ä¿¡åº¦åˆ†æ:")
            print(f"å¹³å‡ç½®ä¿¡åº¦: {np.mean(pred_confidences):.3f}")
            print(f"ç½®ä¿¡åº¦ä¸­ä½æ•°: {np.median(pred_confidences):.3f}")
            print(f"ç½®ä¿¡åº¦æ ‡å‡†å·®: {np.std(pred_confidences):.3f}")
            
            # ç½®ä¿¡åº¦åˆ†å¸ƒ
            print(f"\nç½®ä¿¡åº¦åˆ†å¸ƒ:")
            bins = [0, 0.5, 0.7, 0.9, 1.0]
            bin_labels = ['ä½ (<0.5)', 'ä¸­ (0.5-0.7)', 'é«˜ (0.7-0.9)', 'å¾ˆé«˜ (>0.9)']
            
            for i in range(len(bins)-1):
                count = np.sum((pred_confidences >= bins[i]) & (pred_confidences < bins[i+1]))
                percentage = count / len(pred_confidences) * 100
                print(f"{bin_labels[i]}: {count}ä¸ªæ ·æœ¬ ({percentage:.1f}%)")
            
            # æ­£ç¡®å’Œé”™è¯¯é¢„æµ‹çš„ç½®ä¿¡åº¦å¯¹æ¯”
            correct_mask = (y_pred == y_true)
            if np.sum(correct_mask) > 0:
                correct_mean = np.mean(pred_confidences[correct_mask])
                print(f"æ­£ç¡®é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {correct_mean:.3f}")
            
            incorrect_mask = (y_pred != y_true)
            if np.sum(incorrect_mask) > 0:
                incorrect_mean = np.mean(pred_confidences[incorrect_mask])
                print(f"é”™è¯¯é¢„æµ‹å¹³å‡ç½®ä¿¡åº¦: {incorrect_mean:.3f}")
                
                if np.sum(correct_mask) > 0:
                    print(f"ç½®ä¿¡åº¦å·®å¼‚: {correct_mean - incorrect_mean:.3f}")
    
    def generate_comprehensive_report(self, y_true, y_pred, y_probs, cm):
        """ç”Ÿæˆç»¼åˆè¯„ä¼°æŠ¥å‘Š"""
        from sklearn.metrics import (accuracy_score, precision_score, 
                                   recall_score, f1_score, classification_report)
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_true, y_pred)
        precision = precision_score(y_true, y_pred, average='binary')
        recall = recall_score(y_true, y_pred, average='binary')
        f1 = f1_score(y_true, y_pred, average='binary')
        
        if cm.shape == (1, 1):
            tn, fp, fn, tp = cm[0, 0], 0, 0, 0
        else:
            tn, fp, fn, tp = cm.ravel()
        
        total = len(y_true)
        error_rate = (fp + fn) / total if total > 0 else 0
        
        # ç½®ä¿¡åº¦ç»Ÿè®¡
        if len(y_probs.shape) > 1:
            confidences = np.max(y_probs, axis=1)
            avg_confidence = np.mean(confidences)
            median_confidence = np.median(confidences)
        else:
            avg_confidence = median_confidence = 0
        
        report = f"""ç™½å†…éšœç­›æŸ¥æ¨¡å‹ç»¼åˆè¯„ä¼°æŠ¥å‘Š
{'='*80}

ä¸€ã€åŸºæœ¬ä¿¡æ¯
è¯„ä¼°æ—¶é—´: {np.datetime64('now')}
æ¨¡å‹è·¯å¾„: {self.model_path}
æ•°æ®æ ·æœ¬: {total} ä¸ªæµ‹è¯•æ ·æœ¬

äºŒã€æ€§èƒ½æŒ‡æ ‡æ±‡æ€»
{'='*40}
å‡†ç¡®ç‡ (Accuracy):      {accuracy:.4f} ({accuracy*100:.2f}%)
ç²¾ç¡®ç‡ (Precision):     {precision:.4f} ({precision*100:.2f}%)
å¬å›ç‡ (Recall):        {recall:.4f} ({recall*100:.2f}%)
F1åˆ†æ•° (F1-Score):      {f1:.4f} ({f1*100:.2f}%)
é”™è¯¯ç‡ (Error Rate):    {error_rate:.4f} ({error_rate*100:.2f}%)

ä¸‰ã€æ··æ·†çŸ©é˜µåˆ†æ
{'='*40}
                  é¢„æµ‹æ­£å¸¸    é¢„æµ‹ç™½å†…éšœ
çœŸå®æ­£å¸¸        {tn:>6}        {fp:>6}
çœŸå®ç™½å†…éšœ      {fn:>6}        {tp:>6}

çœŸé˜³æ€§(TP): {tp} (æ­£ç¡®è¯†åˆ«çš„ç™½å†…éšœ)
çœŸé˜´æ€§(TN): {tn} (æ­£ç¡®è¯†åˆ«çš„æ­£å¸¸)
å‡é˜³æ€§(FP): {fp} (æ­£å¸¸è¯¯åˆ¤ä¸ºç™½å†…éšœ)
å‡é˜´æ€§(FN): {fn} (ç™½å†…éšœæ¼è¯Š)

å››ã€ç½®ä¿¡åº¦åˆ†æ
{'='*40}
å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}
ç½®ä¿¡åº¦ä¸­ä½æ•°: {median_confidence:.3f}

äº”ã€æ¨¡å‹è¯„ä»·
{'='*40}
"""
        
        # æ ¹æ®æ€§èƒ½ç»™å‡ºè¯„ä»·
        if accuracy >= 0.95:
            report += "âœ… æ¨¡å‹æ€§èƒ½ä¼˜ç§€ï¼Œéå¸¸é€‚åˆä¸´åºŠåº”ç”¨\n"
        elif accuracy >= 0.90:
            report += "âœ… æ¨¡å‹æ€§èƒ½è‰¯å¥½ï¼Œé€‚åˆä½œä¸ºè¾…åŠ©è¯Šæ–­å·¥å…·\n"
        elif accuracy >= 0.85:
            report += "âš ï¸ æ¨¡å‹æ€§èƒ½ä¸€èˆ¬ï¼Œå»ºè®®è¿›ä¸€æ­¥ä¼˜åŒ–\n"
        else:
            report += "âŒ æ¨¡å‹æ€§èƒ½è¾ƒå·®ï¼Œéœ€è¦é‡æ–°è®­ç»ƒæˆ–è°ƒæ•´\n"
        
        # å»ºè®®
        report += f"""
å…­ã€æ”¹è¿›å»ºè®®
{'='*40}
1. å…³æ³¨å‡é˜´æ€§({fn}ä¸ª): è¿™äº›æ˜¯æ¼è¯Šçš„ç™½å†…éšœç—…ä¾‹ï¼Œä¸´åºŠé£é™©è¾ƒé«˜
2. å…³æ³¨å‡é˜³æ€§({fp}ä¸ª): è¿™äº›æ˜¯è¯¯åˆ¤çš„æ­£å¸¸ç—…ä¾‹ï¼Œå¯èƒ½å¯¼è‡´ä¸å¿…è¦çš„æ£€æŸ¥
"""
        
        if fp > fn:
            report += "3. æ¨¡å‹å€¾å‘äºè¿‡åº¦è¯Šæ–­(å‡é˜³æ€§è¾ƒå¤š)ï¼Œå¯é€‚å½“æé«˜åˆ†ç±»é˜ˆå€¼\n"
        elif fn > fp:
            report += "3. æ¨¡å‹å€¾å‘äºä¿å®ˆè¯Šæ–­(å‡é˜´æ€§è¾ƒå¤š)ï¼Œå¯é€‚å½“é™ä½åˆ†ç±»é˜ˆå€¼\n"
        
        report += f"""
ä¸ƒã€å›¾è¡¨æ–‡ä»¶
{'='*40}
æ‰€æœ‰åˆ†æå›¾è¡¨å·²ä¿å­˜è‡³: {self.charts_dir}
åŒ…å«ä»¥ä¸‹å›¾è¡¨:
01_æ··æ·†çŸ©é˜µ.png           - åˆ†ç±»ç»“æœå¯è§†åŒ–
02_ROCæ›²çº¿.png            - æ¨¡å‹åŒºåˆ†èƒ½åŠ›
03_ç²¾ç¡®ç‡å¬å›ç‡æ›²çº¿.png    - æ¨¡å‹ç²¾ç¡®æ€§
04_é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ.png        - é¢„æµ‹ç½®ä¿¡åº¦åˆ†å¸ƒ
05_æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”.png        - å„ç±»æŒ‡æ ‡å¯¹æ¯”
06_ç½®ä¿¡åº¦åˆ†å¸ƒ.png          - æ­£ç¡®/é”™è¯¯é¢„æµ‹çš„ç½®ä¿¡åº¦
07_é˜ˆå€¼åˆ†æ.png            - é˜ˆå€¼å¯¹æ€§èƒ½çš„å½±å“
08_è®­ç»ƒå†å².png            - æ¨¡å‹è®­ç»ƒè¿‡ç¨‹
09_é”™è¯¯åˆ†ç±»æ ·æœ¬.png        - å…¸å‹é”™è¯¯ç¤ºä¾‹
10_æ€§èƒ½å¯¹æ¯”çŸ©é˜µ.png        - ç»¼åˆæ€§èƒ½å±•ç¤º

{'='*80}
æŠ¥å‘Šç”Ÿæˆå®Œæˆ
{'='*80}
"""
        
        report_file = os.path.join(self.results_dir, 'ç»¼åˆè¯„ä¼°æŠ¥å‘Š.txt')
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"âœ… ç»¼åˆè¯„ä¼°æŠ¥å‘Šå·²ä¿å­˜: {report_file}")
        
        # æ˜¾ç¤ºæŠ¥å‘Šæ‘˜è¦
        print("\nğŸ“‹ æŠ¥å‘Šæ‘˜è¦:")
        print(f"   å‡†ç¡®ç‡: {accuracy*100:.1f}%")
        print(f"   ç²¾ç¡®ç‡: {precision*100:.1f}%")
        print(f"   å¬å›ç‡: {recall*100:.1f}%")
        print(f"   é”™è¯¯æ•°: {fp+fn} ({error_rate*100:.1f}%)")
        print(f"   å›¾è¡¨æ•°: 10ä¸ªè¯¦ç»†åˆ†æå›¾è¡¨")

def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ä¿®å¤å¤æ‚å›¾è¡¨ç‰ˆæ¨¡å‹è¯„ä¼°æ¨¡å—")
    print("="*80)
    
    # è·å–è„šæœ¬ç›®å½•
    base_dir = get_script_dir()
    print(f"è„šæœ¬ç›®å½•: {base_dir}")
    
    # æ£€æŸ¥ä¾èµ–
    try:
        import sklearn
    except ImportError:
        print("âŒ é”™è¯¯: ç¼ºå°‘ scikit-learn æ¨¡å—")
        print("è¯·è¿è¡Œ: pip install scikit-learn")
        response = input("æ˜¯å¦å°è¯•è‡ªåŠ¨å®‰è£…? (y/n): ")
        if response.lower() == 'y':
            import subprocess
            import sys
            try:
                subprocess.check_call([sys.executable, "-m", "pip", "install", "scikit-learn"])
                print("âœ… scikit-learn å®‰è£…æˆåŠŸ")
            except:
                print("âŒ å®‰è£…å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å®‰è£…")
                return
        else:
            return
    
    # æ£€æŸ¥seabornï¼ˆå¯é€‰ï¼‰
    try:
        import seaborn
        print("âœ… seaborn å·²å®‰è£…")
    except ImportError:
        print("âš ï¸ æ³¨æ„: seaborn æœªå®‰è£…ï¼Œéƒ¨åˆ†å›¾è¡¨å¯èƒ½ä¸å¤Ÿç¾è§‚")
        print("   å»ºè®®å®‰è£…: pip install seaborn")
    
    # åˆ›å»ºè¯„ä¼°å™¨
    evaluator = EnhancedCataractModelEvaluator()
    
    # åŠ è½½æ¨¡å‹
    if not evaluator.load_model():
        return
    
    try:
        # æ‰§è¡Œå…¨é¢è¯„ä¼°
        y_true, y_pred, y_probs, y_paths = evaluator.evaluate_model_comprehensive()
        
        print("\n" + "="*80)
        print("ğŸ‰ å…¨é¢è¯„ä¼°å®Œæˆ!")
        print("="*80)
        print(f"\nğŸ“Š ç”Ÿæˆäº†10ä¸ªè¯¦ç»†çš„è¯„ä¼°å›¾è¡¨:")
        print(f"   ä¿å­˜ä½ç½®: {evaluator.charts_dir}")
        print(f"   1. æ··æ·†çŸ©é˜µ")
        print(f"   2. ROCæ›²çº¿")
        print(f"   3. ç²¾ç¡®ç‡-å¬å›ç‡æ›²çº¿")
        print(f"   4. é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒ")
        print(f"   5. æ€§èƒ½æŒ‡æ ‡å¯¹æ¯”")
        print(f"   6. ç½®ä¿¡åº¦åˆ†å¸ƒ")
        print(f"   7. é˜ˆå€¼åˆ†æ")
        print(f"   8. è®­ç»ƒå†å²")
        print(f"   9. é”™è¯¯åˆ†ç±»æ ·æœ¬")
        print(f"   10. æ€§èƒ½å¯¹æ¯”çŸ©é˜µ")
        print(f"\nğŸ“‹ ç”Ÿæˆäº†ç»¼åˆè¯„ä¼°æŠ¥å‘Š:")
        print(f"   ä¿å­˜ä½ç½®: {evaluator.results_dir}/ç»¼åˆè¯„ä¼°æŠ¥å‘Š.txt")
        
    except KeyboardInterrupt:
        print("\n\nâš ï¸ è¯„ä¼°è¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ è¯„ä¼°è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {type(e).__name__}")
        print(f"é”™è¯¯ä¿¡æ¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()